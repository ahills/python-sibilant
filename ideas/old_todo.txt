

special, non-overridable builtins:

(apply expression ([expression*]))
(lambda ([(symbol expression)*]) expression*)
(begin expression*)
(cond (expression expression*)*)
(eval expression)
(define symbol [expression])
(set! symbol expression)
(quote expr)
(quasiquote expr)
(unquote expr)
(splice expr)


1: parsing

use an event-driven parsing mechanism to produce a representation of
sexpr from a stream


2: ast


2.1: handle events to produce the initial abstract syntax tree. This
tree will be comprised of a simplified form of Lists and Atoms


2.2: walk the simple ast from 2.1 to produce a special ast. This tree
will be comprised of Specials and Atoms


2.3: walk the special ast to determine variable scoping (use formals
in lambda, etc)


3: call conformity


the ast will need to be transformed into a chain of (activity, next
link) pairs. Function calls will be transformed to accept their
continuation as a first argument. Application of functions will be
transformed to agree with this convention.


The "result" of each individual evaluation is a pair consisting of the
continuation and data for that continuation.


3.1: transformation of Apply


Apply(fun, arg1, arg2, arg3) becomes
Apply_k(k, fun, arg1, arg2, arg3) -> k1

k1: -> (k2, evaluate fun)
k2 f: -> (k3, evaluate arg1)
k3 a1: -> (k4, evaluate arg2)
k4 a2: -> (k5, evaluate arg3)
k5 a3: -> evaluate f(k, a1, a2, a3)

Apply(fun, Apply(proc1, arg1), arg2) becomes
Apply_k(k, fun, Apply(proc1, arg1), arg2) -> k

k3: -> (k4, evaluate fun)
k4 f: -> evaluate Apply_k(k5, proc1, arg1)
k5 a1: -> (k6, f, a1, evaluate arg2)
k6 a2: -> evaluate f(k, a1, a2)

Apply_k(k5, proc1, arg1) -> k7

k7: -> (k8, evaluate proc1)
k8 p1: -> (k9, p1, evaluate arg1)


3.2 transformation of Begin

Begin(a,b,c...,z) becomes
Begin_k(k, a, b, c... , z) -> k1
k1: evaluate a -> (k2,)
k2: evaluate b -> (k3,)
k3: evaluate c -> (k4,)
k4: -> (k, evaluate z)


3.3 transformation of Lambda


3.4 transformation of Cond


-----


((lambda (a b) (+ a b)) 2 7)

Apply \
  Lambda (a b) \
    Apply \
      +
      a, b
  2, 7


any expression is compiled into a single code object, which is evaluated
by creating a function taking k, where k is fn(*r)


emit block k1 for lambda creation
emit block k2 to evaluate 2 (returns k, 2)
emit block k3 to evaluate 7 (returns k, 7)
emit block k4 to

load const for fun
eval 2
eval 7
apply_k None, fun, 2, 7

-----

I wonder if Spexy may not have been on to something rather
clever. Instead of attempting to emit Python bytecode, maybe emitting
Python syntax and then having *that* become the bytecode really is a
better model. I wouldn't need to be as obscene about is as I was with
Spexy, but I could emit a module-like object that would have the
callable objects embedded. How does that correlate to a compiled
(.pyc) module? Can I go from lisp -> python -> pyc ?

-----

starting from a representation of the AST, create a dispatcher which
will step through the tree, and emit literal python. However, unlike
with spexy, we are allowed to use external imports (spexy builtins
being imported implicitly)

(string or file) -> stream -> event iteration -> \
   ast -> special ast -> \
   python ast -> callable obj -> module instance

parse -> compile -> load

-----

possible idea:

each expression becomes a function definition, honoring the k-passing
call conformity.

the result of a module load is a single function when called with a
globals/locals it executes the content of the function (which is the
module as written) and binds any lambdas etc to the global dict

the global dict can then be considered the module.

-----

note: define works on locals, set! works on whatever it finds first
unless it finds nothing, in which case it sets it in globals


-----

while I'd like to be able to steal the closure cell trickery that
Python uses (operation to load a value from a closure rather than
attempting to resolve by name through nested namespaces), I'm not sure
how well that works with incremental compilation! I need a way to hint
to newly generated interior code that I can supply it with locals for
cells.

-----

2014-05-03

I've lost my direction a bit. Do I really want to care about improper
(dotted) pairs? Should I look for a type-aware dispatch of cons,
instead? Should I aim to be more like Clojure than CL?? How about
symbol namespaces? Should I go for a single namespace, or should I do
a per-module namespace?

-----

2014-06-14

Let's focus on this

- skipping the CPS call conformity compiler for now (make it a
  settable mode, later)
- go straight to compiling into a python AST
- use Pythonic lists, but supply a cons cell (possibly renamed to
  pair)
- adapt the cons call into a generic append/insert
- upward-only continuations when not within the special CPS mode
- still doing import extension from within "normal" python
- still aiming to get bilingual stack traces
- macros to start, defsyntax later
- keyword as subclass of symbol

-----

2014-08-26

The trampoline can be a signalling location, via exceptions. If we use
an exception to signal continuation calling, to signal stack dropping,
and to signal exception handler registration/popping, we can
effectively perform all functions without breaking from normal
exception usage! We can even do cooperative multi-threading with a
yield type exception that causes the trampoline to switch to another
worker continuation context.


-----

2014-10-05

- sibilant
: contains basic types, functions, exceptions

- sibilant.cli
: contains CLI entry points

- sibilant.builtins
: basic functions

- sibilant.ast
: AST for parsing, composing sibilant structure literals

- sibilant.generate
: incremental compilation of sibilant literals into python objects

- sibilant.module
: special module data type that accepts symbols as keys... wait that's
a terrible idea.

- sibilant.cps
: continuation-passing-style stuff, trampoline

- sibilant.cps.kstyle
: contains k-style convention wrappers, decorators, checkers, callers

- sibilant.cps.builtins
: k-style basic functions


# the end.
